# ğŸ™ï¸ Conversational Time Machine

Conversational Time Machine is an **AI-powered interactive application** that allows you to **chat with historical leaders** and listen to their **realistic AI-generated voice responses**.
Currently, the application features **two personas**:
- **Indira Gandhi** (First female Prime Minister of India)
- **Atal Bihari Vajpayee** (Former Prime Minister of India)

---

# ğŸŒ Live Demo
ğŸ”— Try the app now: [web-production-d013b.up.railway.app](web-production-d013b.up.railway.app)

The app is deployed on Railway and ready to use! Simply select a historical figure and start asking questions.

---

## ğŸš€ Features
- **Chat with Historical Figures:** Ask questions and get contextually accurate responses.
- **Voice Responses:** AI-generated voices using **ElevenLabs TTS** for each persona.
- **Conversation History:** Displays the **last 3 questions and answers** with voice playback.
- **RAG (Retrieval-Augmented Generation):** Uses **FAISS** and **Groqâ€™s LLaMA 3.3 model** for persona-based answers.
- **Modern UI:** Beautiful interface built with **Streamlit**.
- **FastAPI Backend:** Manages AI response generation and voice synthesis.

---

## ğŸ›  Tech Stack
- **Frontend:** Streamlit
- **Backend:** FastAPI
- **AI Model:** Groq (LLaMA 3.3 70B)
- **Embeddings & Search:** FAISS Vector Store
- **Text-to-Speech:** ElevenLabs API
- **Language:** Python 3.9+

---

## ğŸ“‚ Project Structure
```yaml

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ faiss_atal/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.faiss
â”‚   â”‚   â”‚   â””â”€â”€ index.pkl
â”‚   â”‚   â”œâ”€â”€ faiss_indira/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.faiss
â”‚   â”‚   â”‚   â””â”€â”€ index.pkl
â”‚   â”‚   â”œâ”€â”€ Atal_Bihari_Vajpayee.pdf
â”‚   â”‚   â”œâ”€â”€ Indira_Gandhi.pdf
â”‚   â”‚   â”œâ”€â”€ atal_g_quotes.txt
â”‚   â”‚   â”œâ”€â”€ atal_g_speeches.txt
â”‚   â”‚   â”œâ”€â”€ quotes.txt
â”‚   â”‚   â””â”€â”€ speeches.txt
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ conversation.py         # Chat API routes
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prepare_embeddings.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py        # For RAG
â”‚   â”‚   â””â”€â”€ tts_service.py        # ElevenLabs TTS service
â”‚   â”œâ”€â”€ static/                   # Generated audio files
â”‚   â”‚   â”œâ”€â”€ atal_39e36c77e34a45b0b3f463... (audio files)
â”‚   â”‚   â”œâ”€â”€ atal_b871bb8165f74af0b7c1f7...
â”‚   â”‚   â”œâ”€â”€ atal_e72c6c4e0db840d68bb25...
â”‚   â”‚   â”œâ”€â”€ atal_response.mp3
â”‚   â”‚   â”œâ”€â”€ indira_733a7532e05b46dcbcf9... (audio files)
â”‚   â”‚   â”œâ”€â”€ indira_b45ee83ad9a7481f9afd...
â”‚   â”‚   â”œâ”€â”€ indira_ca28fd99bf0543498475...
â”‚   â”‚   â”œâ”€â”€ indira_d8342c1ba4fe44388699...
â”‚   â”‚   â””â”€â”€ indira_response.mp3
â”‚   â”œâ”€â”€ main.py                      # FastAPI backend entry point
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ assets/                       # Persona images
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ prompt_templates.py 
â”‚   â”œâ”€â”€ vector_store.py           # FAISS vector loading
â”‚   â””â”€â”€ audio_history.json
â”œâ”€â”€ Procfile
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ debug.py            # For debugging 
â””â”€â”€ debug2.py
```
```

---

## âš™ï¸ Setup & Installation

### 1. Clone the Repository
```bash
git clone [https://github.com/](https://github.com/)jatin019/Conversational-Time-Machine-Project.git
cd conversational-time-machine
```
### 2. Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows
```
### 3. Install Dependencies
```bash
pip install -r requirements.txt
```
### 4. Configure Environment Variables
Create a `.env` file in the root directory and add:
```ini
GROQ_API_KEY=your_groq_api_key
ELEVEN_API_KEY=your_elevenlabs_api_key
INDIRA_VOICE_ID=your_indira_voice_id
ATAL_VOICE_ID=your_atal_voice_id
```
### 5. Run the Backend (FastAPI)
```bash
uvicorn main:app --reload
```
### 6. Run the Frontend (Streamlit)
```bash
streamlit run app.py
```

---

## ğŸŒ Deployment
You can deploy:
- Backend on Render (FastAPI + static audio hosting)
- Frontend on Streamlit Community Cloud

---

## ğŸ–¼ Preview
- Chat with Indira Gandhi or Atal Bihari Vajpayee
- Listen to their voice responses
- View conversation history (last 3 Q&A pairs)

---

## ğŸ¤ Contributing
Pull requests and suggestions are welcome.
For major changes, open an issue first to discuss what youâ€™d like to improve.

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## âœ¨ Credits
- LLaMA 3.3 70B â€“ via Groq API
- ElevenLabs â€“ for AI voice generation
- Streamlit & FastAPI â€“ for frontend and backend
